---
layout:     post                    # 使用的布局（不需要改）
title:      k8s权威指南学习-1            # 标题 
subtitle:   kubernetes                     #副标题
date:       2024-10-26             # 时间
author:     wangyang                     # 作者
header-img: img/post-bg-coffee.jpeg    #这篇文章标题背景图片
catalog: true                       # 是否归档
tags:                               #标签
    - k8s
---

# K8s入门

```
kubectl get nodes
kubectl describe node <node_name>
kubectl get endpoints                //查看pod_ip:container_port信息
kubectl get svc <svc_name> -o yaml   //yaml方式查看
kubectl get pods --all-namespaces    //查看全部命名空间下的pod
kubectl exec -it <pod-name> -c <container_name>  /bin/sh  //不指定容器名就进入pod里的第一个容器
kubectl logs -f <pod-name> -c <container_name>   //不指定容器名就查看pod里的第一个容器

kubeadm config print init-defaults   //输出kubeadm init命令默认参数内容
kubeadm config print join-defaults   //输出kubeadm join命令默认参数内容
kubeadm config images list           //列出所需拉取镜像
kubeadm config images pull           //拉取相关镜像
kubeadm init phase preflight         //init前预检查

docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/<image_name>  //拉取相关镜像
docker pull registry.aliyuncs.com/google_containers/<image_name>              //拉取相关镜像
```

创建命名空间：

```
apiVersion: v1
kind: Namespace
metadata:
  name: development
```

```
kubectl get pod <pod_name> -o wide                            //额外信息
kubectl get pod <pod_name> -o yaml                            //yaml格式
kubectl get pod <pod_name> -o custom-columns=NAME:.metadata.name,RSRC:.metadata.resourceVersion    //修改自定义列名
kubectl get pods --sort-by=.metadata.name                     //根据资源对象名称排序
```

```
kubectl plugin list     //查看当前插件
可以自定义插件，执行文件名以 kubectl- 开头 kubectl-<name>，为该文件添加可执行权限，复制该文件到$PATH目录，一般是/usr/local/bin下，执行 kubectl name 执行自定义插件
```



## Configmap

### configmap创建

1、YAML方式

```
apiVersion: v1
kind: ConfigMap
metadata:
  name: cm-appvars
data:
  apploglevel: info
  appdatadir: /var/data
```

2、kubectl方式

```
kubectl create configmap <configmap_name> --from-file=<file_name>    
通过文件创建，key为文件名，value为文件内容
kubectl create configmap <configmap_name> --from-file=<dir_name> 
通过目录创建，key为目录下文件名，value为文件内容
kubectl create configmap <configmap_name> --from-literal=key1=value1
通过文本创建，直接指定key,value
```



### pod使用configmap

1、通过环境变量方式使用

```
apiVersion: v1
kind: Pod
metadata:
  name: cm-test-pod
spec:
  containers:
  - name: cm-test
    image: busybox
    command: [ "/bin/sh", "-c", "env" ]
    envFrom:                                   //将所有定义key=value自动生成环境变量
    - configMapRef:
       name: cm-appvars
  restartPolicy: Never
```



2、通过Volume挂载方式将ConfigMap 内容挂载为容器内部文件或者目录，key为文件名，value则为内容

```
apiVersion: v1
kind: Pod
metadata:
  name: cm-test-app
spec:
  containers:
  - name: cm-test-app
    image: kubeguide/tomcat-app:v1
    imagePullPolicy: Never
    ports:
    - containerPort: 8080
    volumeMounts:
    - name: serverxml
      mountPath: /configfiles
  volumes:
  - name: serverxml
    configMap:
      name: cm-appconfigfiles
```



### 容器内获取pod信息

1、环境变量：将pod或者container信息设置为容器内的环境变量

```
apiVersion: v1
kind: Pod
metadata:
  name: dapi-envars-fieldref
spec:
  containers:
    - name: test-container
      image: busybox
      command: [ "sh", "-c"]
      args:
      - while true; do
          echo -en '\n';
          printenv MY_NODE_NAME MY_POD_NAME MY_POD_NAMESPACE;
          printenv MY_CPU_REQUEST MY_CPU_LIMIT;
          sleep 10;
        done;
      env:
        - name: MY_NODE_NAME
          valueFrom:
            fieldRef:
              fieldPath: spec.nodeName
        - name: MY_POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: MY_POD_NAMESPACE
          valueFrom:
            fieldRef:                                     //pod信息
              fieldPath: metadata.namespace
        - name: MY_CPU_REQUEST
          valueFrom:
            resourceFieldRef:                             //container信息
              containerName: test-container
              resource: requests.cpu
        - name: MY_CPU_LIMIT
          valueFrom:
            resourceFieldRef:
              containerName: test-container
              resource: limits.cpu
  restartPolicy: Never
```

2、volume挂载：将pod或者container信息以文件形式挂载到容器内部

```
apiVersion: v1
kind: Pod
metadata:
  name: kubernetes-downwardapi-volume-example
  labels:
    zone: us-est-coast
    cluster: test-cluster1
  annotations:
    build: two
    builder: john-doe
spec:
  containers:
    - name: client-container
      image: busybox
      command: ["sh", "-c"]
      args:
      - while true; do
            echo -en '\n\n'; cat /etc/podinfo/labels; 
            echo -en '\n\n'; cat /etc/podinfo/annotations; 
            echo -en '\n\n'; cat /etc/podinfo/cpu_limit;
            echo -en '\n\n'; cat /etc/podinfo/cpu_request;
          sleep 5;
        done;
      volumeMounts:
        - name: podinfo
          mountPath: /etc/podinfo
  volumes:
    - name: podinfo
      downwardAPI:
        items:
          - path: "labels"
            fieldRef:                                //pod信息
              fieldPath: metadata.labels
          - path: "annotations"
            fieldRef:
              fieldPath: metadata.annotations
          - path: "cpu_limit"
            resourceFieldRef:                        //container信息
              containerName: client-container
              resource: limits.cpu
              divisor: 1m
          - path: "cpu_request"
            resourceFieldRef:
              containerName: client-container
              resource: requests.cpu
              divisor: 1m
```



## 健康检查

LivenessProbe：存活探测

ReadinessProbe：可用探测

StartupProbe：首次就绪探测

三种检测方式：

```
# exec
---
apiVersion: v1
kind: Pod
metadata:
  labels:
    test: liveness
  name: liveness-exec
spec:
  containers:
  - name: liveness
    image: gcr.io/google_containers/busybox
    args:
    - /bin/sh
    - -c
    - echo ok > /tmp/health; sleep 10; rm -rf /tmp/health; sleep 600
    livenessProbe:
      exec:
        command:
        - cat
        - /tmp/health
      initialDelaySeconds: 15              //启动容器首次健康检查时间
      timeoutSeconds: 1                    //健康检查发送请求后等待响应超时时间



# tcpsocket
---
apiVersion: v1
kind: Pod
metadata:
  name: pod-with-healthcheck
spec:
  containers:
  - name: nginx
    image: nginx
    ports:
    - containerPort: 80
    livenessProbe:
      tcpSocket:
        port: 80
      initialDelaySeconds: 30
      timeoutSeconds: 1



# http
---
apiVersion: v1
kind: Pod
metadata:
  name: pod-with-healthcheck
spec:
  containers:
  - name: nginx
    image: nginx
    ports:
    - containerPort: 80
    livenessProbe:
      httpGet:
        path: /_status/healthz
        port: 80
      initialDelaySeconds: 30
      timeoutSeconds: 1
```



## pod调度器

### Deployment或RC

RC：标签选择器只能选择一个标签

RS：集合式的标签选择器

```
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
spec:
  selector:
    matchLabels:
      app: nginx
  replicas: 3
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.7.9
        ports:
        - containerPort: 80
```

```
kubectl get deployments
kubectl get rs
kubectl get pods
```



### NodeSelector

```
kubectl label nodes <node_name>  <key>=<value>
```

```
apiVersion: v1
kind: ReplicationController 
metadata:
  name: redis-master
  labels:
    name: redis-master 
spec:
  replicas: 1
  selector:
    name: redis-master
  template:
    metadata:
      labels:
        name: redis-master
    spec:
      containers:
      - name: master
        image: kubeguide/redis-master:v1
        ports:
        - containerPort: 6379
      nodeSelector:
        zone: north
```



### NodeAffinity Node亲和性调度

亲和性调度使用软限制、优先采用等限制方式代替之前NodeSelector硬限制，在不满足优先需求情况下，会继续运行pod

```
apiVersion: v1
kind: Pod
metadata:
  name: with-node-affinity
spec:
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:        //必须满足，硬限制
        nodeSelectorTerms:                  //定义多个nodeSelectorTerms，其中一个匹配成功即可
        - matchExpressions:   //同个nodeSelectorTerms下有多个matchExpressions，需全部满足才能运行
          - key: kubernetes.io/arch
            operator: In           //操作符
            values:
            - amd64
      preferredDuringSchedulingIgnoredDuringExecution:       //优先满足，软限制
      - weight: 1
        preference:
          matchExpressions:
          - key: disk-type
            operator: In
            values:
            - ssd
  containers:
  - name: with-node-affinity
    image: gcr.io/google_containers/pause:2.0
```

### podAffinity 亲和和 podAntiAffinity互斥调度策略

相关联的两种或多种Pod是否在同一个拓扑域中共存或者互斥

默认拓扑域

Kubernetes.io/hostname

Topology.kubernetes.io/region

Topology.kubernetes.io/zone

```
# target pod
---
apiVersion: v1
kind: Pod
metadata:
  name: pod-flag
  labels:
    security: "S1"
    app: "nginx"
spec:
  containers:
  - name: nginx
    image: nginx



# affinity
---
apiVersion: v1
kind: Pod
metadata:
  name: pod-affinity
spec:
  affinity:
    podAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:   
      - labelSelector:
          matchExpressions:
          - key: security
            operator: In
            values:
            - S1
        topologyKey: kubernetes.io/hostname               //和目标pod拓扑域是否亲和或互斥
  containers:
  - name: with-pod-affinity
    image: gcr.io/google_containers/pause:2.0




# anti-affinity
---
apiVersion: v1
kind: Pod
metadata:
  name: anti-affinity
spec:
  affinity:
    podAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchExpressions:
          - key: security
            operator: In
            values:
            - S1
        topologyKey: topology.kubernetes.io/zone
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchExpressions:
          - key: app
            operator: In
            values:
            - nginx
        topologyKey: kubernetes.io/hostname
  containers:
  - name: anti-affinity
    image: gcr.io/google_containers/pause:2.0
```

### Taints和Tolerations （污点和容忍）

Node节点设置Taints，拒绝Pod的运行

Pod上设置Tolerations，容忍Taints

```
# can be scheduled to node1

$ kubectl taint nodes node1 key=value:NoSchedule         //node1设置污点

---
apiVersion: v1
kind: Pod
metadata:
  name: pod-toleration
spec:
  tolerations:
  - key: "key"
    operator: "Equal"
    value: "value"
    effect: "NoSchedule"                                 //pod容忍污点
  containers:
  - name: pod-toleration
    image: gcr.io/google_containers/pause:2.0

---         
  tolerations:                                           //pod容忍污点
  - key: "key" 
    operator: "Exists"
    effect: "NoSchedule"


# can't be scheduled to node1

$ kubectl taint nodes node1 key1=value1:NoSchedule       //不调度，针对scheduler而言
$ kubectl taint nodes node1 key1=value1:NoExecute        //驱逐，针对kubelet而言
$ kubectl taint nodes node1 key2=value2:NoSchedule

---
  tolerations:
  - key: "key1"
    operator: "Equal"
    value: "value1"
    effect: "NoSchedule"
  - key: "key1"
    operator: "Equal"
    value: "value1"
    effect: "NoExecute"
```

### Pod Priority Preemption： Pod 优先级调度抢占

```
---
apiVersion: scheduling.k8s.io/v1beta1
kind: PriorityClass                         //优先级
metadata:
  name: high-priority
value: 1000000
globalDefault: false
description: "This priority class should be used for XYZ service pods only."


---
apiVersion: v1
kind: Pod
metadata:
  name: nginx
  labels:
    env: test
spec:
  containers:
  - name: nginx
    image: nginx
    imagePullPolicy: IfNotPresent
  priorityClassName: high-priority          //设置pod优先级
```

### DaemonSet 在每个Node上都调度一个pod

```
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: fluentd-cloud-logging
  namespace: kube-system
  labels:
    k8s-app: fluentd-cloud-logging
spec:
  selector:
    matchLabels:
      k8s-app: fluentd-cloud-logging
  template:
    metadata:
      namespace: kube-system
      labels:
        k8s-app: fluentd-cloud-logging
    spec:
      containers:
      - name: fluentd-cloud-logging
        image: gcr.io/google_containers/fluentd-elasticsearch:1.17
        resources:
          limits:
            cpu: 100m
            memory: 200Mi
        env:
        - name: FLUENTD_ARGS
          value: -q
        volumeMounts:
        - name: varlog
          mountPath: /var/log
          readOnly: false
        - name: containers
          mountPath: /var/lib/docker/containers
          readOnly: false
      volumes:
      - name: containers
        hostPath:
          path: /var/lib/docker/containers
      - name: varlog
        hostPath:
          path: /var/log
```

### Job 批处理调度

``` 
apiVersion: batch/v1
kind: Job
metadata:
  name: process-item-$ITEM
  labels:
    jobgroup: jobexample
spec:
  template:
    metadata:
      name: jobexample
      labels:
        jobgroup: jobexample
    spec:
      containers:
      - name: c
        image: busybox
        command: ["sh", "-c", "echo Processing item $ITEM && sleep 5"]
      restartPolicy: Never

//生成批处理文件  
for i in a b c 
do 
  cat job.yaml.txt | sed "s/\$ITEM/$i" > jobs/job-$i.yaml
done
//执行批处理文件
kubectl apply -f jobs
```

### Cronjob 定时任务

```
apiVersion: batch/v1
kind: CronJob
metadata:
  name: hello
spec:
  schedule: "*/1 * * * *"                //每分钟执行一次
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: hello
            image: busybox
            args:
            - /bin/sh
            - -c
            - date; echo Hello from the Kubernetes cluster
          restartPolicy: OnFailure
          
          
kubectl get cronjob <cronjob_name>
kubectl get jobs --watch       //动态查看执行历史和现状
kubectl delete cronjob <cronjob_name>
```

### Init Container 初始化容器

容器启动前初始化操作

```
apiVersion: v1
kind: Pod
metadata:
  name: nginx
  annotations:
spec:
  initContainers:                             //容器启动前初始化操作
  - name: install
    image: busybox
    command:
    - wget
    - "-O"
    - "/work-dir/index.html"
    - http://kubernetes.io
    volumeMounts:
    - name: workdir
      mountPath: "/work-dir"
  containers:
  - name: nginx
    image: nginx
    ports:
    - containerPort: 80
    volumeMounts:
    - name: workdir
      mountPath: /usr/share/nginx/html
  dnsPolicy: Default
  volumes:
  - name: workdir
    emptyDir: {}
```

### Pod的升级和回滚

如果pod是由deployment创建的，可以通过更新yaml文件来完成升级

```
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
spec:
  selector:
    matchLabels:
      app: nginx
  replicas: 3
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.12
        ports:
        - containerPort: 80
```

```
# 更新pod定义文件
kubectl set image deployment/nginx-deployment nginx=nginx:latest
kubectl edit deployment/nginx-deployment

# 查看实时滚动更新过程
kubectl rollout status deployment/nginx-deployment

#查看deployment更新过程
kubectl describe deployment nginx-deployment

#maxUnavailable 和 maxSurge  绝对值或者百分比
maxUnavailable:pod最大不可用数量，对于旧rs而言
maxSurge:更新pod过程中pod总数量比所需副本数量差值，对于新rs而言


# rollback 回滚
kubectl rollout history deployment/nginx-deployment  //查看deployment历史部署记录
每次修改deployment资源时，带上--record命令,history的CHANGE-CAUSE就可以看到每次执行的命令
kubectl rollout history deployment/nginx-deployment --revision=3  //查看特定历史版本详细信息
kubectl rollout undo deployment/nginx-deployment           //回滚到上个版本
kubectl rollout undo deployment/nginx-deployment --to-revision=2  //回滚到指定版本


# pause and resume  暂停和恢复Deployment的部署操作，避免频繁触发deployment更新操作
kubectl rollout pause deployment/nginx-deployment           //暂停deploymnet更新操作
kubectl set image deploy/nginx-deployment nginx=nginx:1.9.1  //更新deployment，不触发更新
kubectl rollout history deploy/nginx-deployment              //查看历史记录未触发更新
kubectl set resources deployment nginx-deployment -c=nginx --limits=cpu=200m,memory=512Mi  //第二次更新deployment参数，不触发更新
kubectl rollout resume deploy nginx-deployment              //恢复deploymnet更新
```

### Pod的扩缩容

手动模式：运行kubectl scale 命令或者通过 RESTful API 对Deployment/RC进行Pod数量的设置

自动模式：需要用户根据某个性能指标或者自定义业务指标，并指定Pod副本的数量范围，系统将自动在这个范围内根据性能指标变化进行调整



手动扩缩容机制

```
kubectl scale deployment nginx-deployment --replicas 5
kubectl scale deployment nginx-deployment --replicas=1
```



自动扩缩容机制

HPA控制器，基于CPU使用率进行自动Pod扩缩容



### 新克隆节点加入集群

新克隆节点加入集群

```
修改IP、名称、/etc/hosts

停止并禁用 containerd 服务
sudo systemctl stop containerd
sudo systemctl disable containerd

清除身份信息
sudo KUBEADM_CRI_SOCKET=unix:///var/run/cri-dockerd.sock kubeadm reset

master节点执行
kubeadm token create --print-join-command

新node节点执行
kubeadm join 192.168.230.128:6443 --token zwqw3x.vgyl9gqvjauijyoo --discovery-token-ca-cert-hash sha256:af88d5a50f4bd2d6122312841747b7b2d7cd85c32dc1f503c72wsdxce509  --cri-socket /var/run/cri-dockerd.sock

启用并自启 containerd 服务
sudo systemctl start containerd
sudo systemctl enable containerd
```



```
{
        "_port_comment": "Heketi Server Port Number",
        "port" : "8080",

        "_use_auth": "Enable JWT authorization. Please enable for deployment",
        "use_auth" : false,

        "_jwt" : "Private keys for access",
        //"jwt" : {
        //      "_admin" : "Admin has access to all APIs",
        //      "admin" : {
        //              "key" : "My Secret"
        //      },
        //      "_user" : "User only has access to /volumes endpoint",
        //      "user" : { 
        //              "key" : "My Secret"
        //      }
        //},

        "_glusterfs_comment": "GlusterFS Configuration",
        "glusterfs" : {

                "_executor_comment": "Execute plugin. Possible choices: mock, ssh",
                "executor" : "mock",

                "_db_comment": "Database file name",
                "db" : "/var/lib/heketi/heketi.db"
        }
}
```

